<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Eric Nalisnick | University of Amsterdam</title>
		<link rel="stylesheet" href="style.css">
		<style>
			.markdown-body {
				box-sizing: border-box;
				min-width: 200px;
				max-width: 980px;
				margin: 0 auto;
				padding: 45px;
			}
			@media (max-width: 767px) {
				.markdown-body {
					padding: 15px;
				}
				.left {
			    width: 100%;
			  }
			  .right {
			    width: 100%;
			  }
				.portrait {
					margin-bottom: 1em;
			  }
			}
			html {
			  width: 100vw;
			}
			body {
			  overflow-x: hidden;
			}
		</style>
	</head>
	<body class="markdown-body">
	  <h2>Human-in-the-Loop Machine Learning</h2>
	  <h4>Course Coordinators: <a href="https://enalisnick.github.io/">Eric Nalisnick</a> and <a href="https://aliannejadi.com/">Mohammad Aliannejadi</a></h4>
	  <h4>MSc AI, Semester 1, Block 2, 2023</h4>

	  
	  <p>Machine learning (ML) is being deployed in increasingly consequential tasks, such as healthcare and autonomous driving.  For the foreseeable future, successfully deploying ML in such settings will require close collaboration and integration with humans, whether they be users, designers, engineers, policy-makers, etc.  This course will look at how humans can be incorporated into the foundations of ML in a principled way.  The course will be broken down (unequally) into three parts: <i>demonstration</i>, <i>collaboration</i>, and <i>oversight</i>.  Demonstration is about how machines can learn from `watching' humans---such as learning to drive a car from data collected while humans drive.  In this setting, the human is assumed to be strictly better than the machine and so the primary goal is to transmit the human's knowledge and abilities into the ML model.  The second part, collaboration, is about when humans and models are near equals in performance but not in abilities.  A relevant setting is AI-assisted healthcare: perhaps a human radiologist and ML model are good at diagnosising different kinds of patients.  Thus we will look at methodologies that allow machines to `ask for help' when they are either unconfident in their performance and/or think the human can better carry out the task.  Lastly, the course will close with the  setting in which machines are strictly better at a task than humans, but we still wish to monitor them to ensure safety (oversight).</p>  


	</body>
</html>

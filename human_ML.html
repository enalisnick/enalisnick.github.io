<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Human-in-the-Loop Machine Learning | University of Amsterdam</title>
		<link rel="stylesheet" href="style.css">
		<style>
			.markdown-body {
				box-sizing: border-box;
				min-width: 200px;
				max-width: 980px;
				margin: 0 auto;
				padding: 45px;
			}
			@media (max-width: 767px) {
				.markdown-body {
					padding: 15px;
				}
				.left {
			    width: 100%;
			  }
			  .right {
			    width: 100%;
			  }
				.portrait {
					margin-bottom: 1em;
			  }
			}
			html {
			  width: 100vw;
			}
			body {
			  overflow-x: hidden;
			}
		</style>
	</head>
	<body class="markdown-body">
	  <h2>Human-in-the-Loop Machine Learning</h2>
	  University of Amsterdam</br>
	  Masters of AI: Semester 1, Block 2, 2023</br>
	  Course Coordinators: <a href="https://enalisnick.github.io/">Eric Nalisnick</a> and <a href="https://aliannejadi.com/">Mohammad Aliannejadi</a></br>
	  Teaching Assistants: <a href="https://rajevv.github.io/">Rajeev Verma</a>, <a href="https://dvtailor.github.io/">Dharmesh Tailor<a>, <a href="http://amlab.science.uva.nl/people/AlexanderTimans/">Alexander Timans<a></br>
          Notes: <a href="ML_with_Humans_Course_Notes.pdf">ML_with_Humans_Course_Notes.pdf</a></br>
	  </br>

	  
		  <p>Machine learning (ML) is being deployed in increasingly consequential tasks, such as healthcare and autonomous driving.  For the foreseeable future, successfully deploying ML in such settings will require close collaboration and integration with humans, whether they be users, designers, engineers, policy-makers, etc.  This course will look at how humans can be incorporated into the foundations of ML in a principled way.  The course will be broken down (unequally) into three parts: <i>demonstration</i>, <i>collaboration</i>, and <i>oversight</i>.  Demonstration is about how machines can learn from 'observing' humans---such as learning to drive a car from data collected while humans drive.  In this setting, the human is assumed to be strictly better than the machine and so the primary goal is to transmit the human's knowledge and abilities into the ML model.  The second part, collaboration, is about when humans and models are near equals in performance but not in abilities.  A relevant setting is AI-assisted healthcare: perhaps a human radiologist and ML model are good at diagnosising different kinds of diseases.  Thus we will look at methodologies that allow machines to `ask for help' when they are either unconfident in their own performance and/or think the human can better carry out the task.  Lastly, the course will close with the setting in which machines are strictly better at a task than humans are, but we still wish to monitor them to ensure safety and alignment with our goals (oversight).</p>

	      <center><h3>Schedule and Topics</h3></center>
	      <table style="width: 100%">
		<thead>
		  <tr>
		    <th>Dates</th>
		    <th>Topics</th>
		    <th>Readings</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <td>31.10.23</td>
		    <td>Logistics, introduction, building prior knowledge into models</td>
		    <td>
		      <ol>
			<li><a href="https://staff.fnwi.uva.nl/m.welling/wp-content/uploads/Model-versus-Data-AI-1.pdf" target="_blank" rel="noopener noreferrer"><i>Do we still need models or just more data and compute?</i> by Welling</a></li>
			<li><a href="https://bayes.wustl.edu/etj/articles/prior.pdf" target="_blank" rel="noopener noreferrer"><i>Prior Probabilities</i> by Jaynes</a></li>
		      </ol>
		  </tr>
		  <tr>
		    <td>02.11.23</td>
		    <td>Crowdsourcing, Dawid-Skene model</td>
		    <td>
		      <ol>
			<li><a href="https://canvas.northwestern.edu/courses/65895/files/4174911/download?verifier=lUyedGR8Yb7I4NwFOtosvJqir8Oc6huVBwBgI5ko&wrap=1" target="_blank" rel="noopener noreferrer"><i>Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm</i> by Dawid &amp; Skene</a></li>
			<li><a href="https://jmlr.csail.mit.edu/papers/v11/raykar10a.html" target="_blank" rel="noopener noreferrer"><i>Learning From Crowds</i> by Raykar et al.</a></li>
			<li><a href="https://arxiv.org/abs/1703.08774" target="_blank" rel="noopener noreferrer"><i>Who Said What: Modeling Individual Labelers Improves Classification</i> by Guan et al.</a></li>
		      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>07.11.23</td>
		    <td>Active learning</td>
		    <td>
		      <ol>
			<li><a href="https://minds.wisconsin.edu/handle/1793/60660" target="_blank" rel="noopener noreferrer"><i>Active Learning Literature Survey</i> by Settles</a></li>
			<li><a href="https://icml.cc/Conferences/2011/papers/596_icmlpaper.pdf" target="_blank" rel="noopener noreferrer"><i>Active Learning from Crowds</i> by Yan et al.</a></li>
		      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>09.11.23</td>
		    <td>Practical on crowdsourcing platforms, overview of reinforcement learning (RL)</td>
		    <td>
		      <ol>
                        <li><a href="https://www.davidsilver.uk/teaching/" target="_blank" rel="noopener noreferrer"><i>Lecture 1: Introduction to RL</i> by Silver</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>14.11.23</td>
		    <td>Imitation learning: behavior cloning, distribution matching</td>
		    <td>
		      <ol>
			<li><a href="https://web.stanford.edu/class/cs237b/pdfs/lecture/cs237b_lecture_12.pdf" target="_blank" rel="noopener noreferrer">Notes on Imitation Learning, CS237B, Stanford University</a></li>
			<li><a href="https://spiral.imperial.ac.uk/bitstream/10044/1/12213/4/icra2013.pdf" target="_blank" rel="noopener noreferrer"><i>Model-Based Imitation Learning by Probabilistic Trajectory Matching</i> by Englert et al.</a></li>
			<li><a href="https://arxiv.org/abs/1606.03476" target="_blank" rel="noopener noreferrer"><i>Generative Adversarial Imitation Learning</i> by Ho &amp; Ermon</a></li>
		      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>16.11.23</td>
		    <td>Imitation learning continued: distribution matching (cont.), inverse RL</td>
		    <td>
		      <ol>
                        <li><a href="https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf" target="_blank" rel="noopener noreferrer"><i>Apprenticeship Learning via Inverse Reinforcement Learning</i> by Abbeel &amp; Ng</a></li>
			<li><a href="https://cdn.aaai.org/AAAI/2008/AAAI08-227.pdf" target="_blank" rel="noopener noreferrer"><i>Maximum Entropy Inverse Reinforcement Learning</i> by Ziebart et al.</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>21.11.23</td>
		    <td>Inverse RL continued, RL from human feedback</td>
		    <td>
		      <ol>
                        <li><a href="https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html" target="_blank" rel="noopener noreferrer"><i>Deep Reinforcement Learning from Human Preferences</i> by Christiano et al.</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>23.11.23</td>
		    <td>Direct preference optimization, exam review</td>
		    <td>
		      <ol>
			<li><a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noopener noreferrer"><i>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</i> by Rafailov et al.</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>30.11.23</td>
		    <td colspan="2"><center>Exam</center></td>
		  </tr>
		  <tr>
		    <td>05.12.23</td>
		    <td>Guest lectures: large language models by <a href="https://plg.uwaterloo.ca/~claclark/">Prof. Charlie Clarke (Univ. of Waterloo)</a> and the alignment problem by <a href="https://langleon.github.io/">Leon Lang (UvA)</a></td>
		    <td>
		      <ol>
                        <li><a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noopener noreferrer"><i>Perspectives on Large Language Models for Relevance Judgment</i> by Faggioli et al.</a></li>
			<li><a href="https://arxiv.org/abs/2209.00626" target="_blank" rel="noopener noreferrer"><i>The Alignment Problem from a Deep Learning Perspective</i> by Ngo et al.</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>07.12.23</td>
		    <td>Combining human and machine predictions, learning to defer to an expert</td>
		    <td>
		      <ol>
                        <li><a href="https://www.ijcai.org/Proceedings/16/Papers/603.pdf" target="_blank" rel="noopener noreferrer"><i>Directions in Hybrid Intelligence: Complementing AI Systems with Human Intelligence</i> by Kamar</a></li>
			<li><a href="https://papers.nips.cc/paper/2021/hash/234b941e88b755b7a72a1c1dd5022f30-Abstract.html" target="_blank" rel="noopener noreferrer"><i>Combining Human Predictions with Model Probabilities via Confusion Matrices and Calibration</i> by Kerrigan et al.</a></li>
			<li><a href="https://arxiv.org/abs/2005.00582" target="_blank" rel="noopener noreferrer"><i>Learning to Complement Humans</i> by Wilder et al.</a></li>
			<li><a href="https://proceedings.mlr.press/v119/mozannar20b.html" target="_blank" rel="noopener noreferrer"><i>Consistent Estimators for Learning to Defer to an Expert</i> by Mozannar &amp; Sontag</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>12.12.23</td>
		    <td><a href="off_switch_game_lecture.pdf">The off-switch game (slides)<a></td>
		    <td>
		      <ol>
                        <li><a href="https://intelligence.org/files/Corrigibility.pdf" target="_blank" rel="noopener noreferrer"><i>Corrigibility</i> by Soares et al.</a></li>
			<li><a href="https://arxiv.org/abs/1611.08219" target="_blank" rel="noopener noreferrer"><i>The Off-Switch Game</i> by Hadfield-Menell et al.</a></li>
                      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>14.12.23</td>
		    <td>Off-switch game continued, human control (causal definitions), course summary</td>
		    <td>
		      <ol>
                        <li><a href="https://arxiv.org/abs/2305.19861" target="_blank" rel="noopener noreferrer"><i>Human Control: Definitions and Algorithms</i> by Carey &amp; Everitt.</a></li>
                      </ol>
		    </td>
		  </tr>
		</tbody>
	      </table>

	</body>
</html>
